{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.1.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -U -q open-deep-research #! works in terminal not in jupyter notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "above: installing open deep research\n",
    "below: import open deep research"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0.15\n"
     ]
    }
   ],
   "source": [
    "import open_deep_research   \n",
    "print(open_deep_research.__version__) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "first line: only needed for jupyter\n",
    "other 3 just importing functionalities "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image, display\n",
    "from langgraph.types import Command\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from open_deep_research.graph import builder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "initiate memory and compiling graph\n",
    "display is a jupyter notebook command\n",
    "mermaid is just something people use to draw "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "memory = MemorySaver()\n",
    "graph = builder.compile(checkpointer=memory)\n",
    "display(Image(graph.get_graph(xray=1).draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "more imports \n",
    "set environment variable\n",
    "groq (recommended since free yippee)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, getpass\n",
    "\n",
    "def _set_env(var: str):\n",
    "    if not os.environ.get(var):\n",
    "        os.environ[var] = getpass.getpass(f\"{var}: \")\n",
    "\n",
    "# Set the API keys used for any model or search tool selections below, such as:\n",
    "# _set_env(\"OPENAI_API_KEY\")\n",
    "# _set_env(\"ANTHROPIC_API_KEY\")\n",
    "# _set_env(\"TAVILY_API_KEY\")\n",
    "# _set_env(\"GROQ_API_KEY\")\n",
    "# _set_env(\"PERPLEXITY_API_KEY\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "define report structure\n",
    "threads: (second one uses groq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "APIStatusError",
     "evalue": "Error code: 413 - {'error': {'message': 'Request too large for model `llama-3.3-70b-versatile` in organization `org_01jvm4g19ye79b5d2ax2wmsvac` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Requested 30287, please reduce your message size and try again. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAPIStatusError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 55\u001b[0m\n\u001b[1;32m     53\u001b[0m end_status \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m     54\u001b[0m \u001b[38;5;66;03m# Run the graph until the interruption\u001b[39;00m\n\u001b[0;32m---> 55\u001b[0m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m event \u001b[38;5;129;01min\u001b[39;00m graph\u001b[38;5;241m.\u001b[39mastream({\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtopic\u001b[39m\u001b[38;5;124m\"\u001b[39m:topic}, thread, stream_mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mupdates\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m     56\u001b[0m    \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m__interrupt__\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m event:\n\u001b[1;32m     57\u001b[0m       interrupt_value \u001b[38;5;241m=\u001b[39m event[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m__interrupt__\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mvalue\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/langgraph/pregel/__init__.py:2655\u001b[0m, in \u001b[0;36mPregel.astream\u001b[0;34m(self, input, config, stream_mode, output_keys, interrupt_before, interrupt_after, checkpoint_during, debug, subgraphs)\u001b[0m\n\u001b[1;32m   2649\u001b[0m \u001b[38;5;66;03m# Similarly to Bulk Synchronous Parallel / Pregel model\u001b[39;00m\n\u001b[1;32m   2650\u001b[0m \u001b[38;5;66;03m# computation proceeds in steps, while there are channel updates\u001b[39;00m\n\u001b[1;32m   2651\u001b[0m \u001b[38;5;66;03m# channel updates from step N are only visible in step N+1\u001b[39;00m\n\u001b[1;32m   2652\u001b[0m \u001b[38;5;66;03m# channels are guaranteed to be immutable for the duration of the step,\u001b[39;00m\n\u001b[1;32m   2653\u001b[0m \u001b[38;5;66;03m# with channel updates applied only at the transition between steps\u001b[39;00m\n\u001b[1;32m   2654\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m loop\u001b[38;5;241m.\u001b[39mtick(input_keys\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_channels):\n\u001b[0;32m-> 2655\u001b[0m     \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m runner\u001b[38;5;241m.\u001b[39matick(\n\u001b[1;32m   2656\u001b[0m         loop\u001b[38;5;241m.\u001b[39mtasks\u001b[38;5;241m.\u001b[39mvalues(),\n\u001b[1;32m   2657\u001b[0m         timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstep_timeout,\n\u001b[1;32m   2658\u001b[0m         retry_policy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mretry_policy,\n\u001b[1;32m   2659\u001b[0m         get_waiter\u001b[38;5;241m=\u001b[39mget_waiter,\n\u001b[1;32m   2660\u001b[0m     ):\n\u001b[1;32m   2661\u001b[0m         \u001b[38;5;66;03m# emit output\u001b[39;00m\n\u001b[1;32m   2662\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m o \u001b[38;5;129;01min\u001b[39;00m output():\n\u001b[1;32m   2663\u001b[0m             \u001b[38;5;28;01myield\u001b[39;00m o\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/langgraph/pregel/runner.py:288\u001b[0m, in \u001b[0;36mPregelRunner.atick\u001b[0;34m(self, tasks, reraise, timeout, retry_policy, get_waiter)\u001b[0m\n\u001b[1;32m    286\u001b[0m t \u001b[38;5;241m=\u001b[39m tasks[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    287\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 288\u001b[0m     \u001b[38;5;28;01mawait\u001b[39;00m arun_with_retry(\n\u001b[1;32m    289\u001b[0m         t,\n\u001b[1;32m    290\u001b[0m         retry_policy,\n\u001b[1;32m    291\u001b[0m         stream\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39muse_astream,\n\u001b[1;32m    292\u001b[0m         configurable\u001b[38;5;241m=\u001b[39m{\n\u001b[1;32m    293\u001b[0m             CONFIG_KEY_CALL: partial(\n\u001b[1;32m    294\u001b[0m                 _acall,\n\u001b[1;32m    295\u001b[0m                 weakref\u001b[38;5;241m.\u001b[39mref(t),\n\u001b[1;32m    296\u001b[0m                 stream\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39muse_astream,\n\u001b[1;32m    297\u001b[0m                 retry\u001b[38;5;241m=\u001b[39mretry_policy,\n\u001b[1;32m    298\u001b[0m                 futures\u001b[38;5;241m=\u001b[39mweakref\u001b[38;5;241m.\u001b[39mref(futures),\n\u001b[1;32m    299\u001b[0m                 schedule_task\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mschedule_task,\n\u001b[1;32m    300\u001b[0m                 submit\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msubmit,\n\u001b[1;32m    301\u001b[0m                 reraise\u001b[38;5;241m=\u001b[39mreraise,\n\u001b[1;32m    302\u001b[0m                 loop\u001b[38;5;241m=\u001b[39mloop,\n\u001b[1;32m    303\u001b[0m             ),\n\u001b[1;32m    304\u001b[0m         },\n\u001b[1;32m    305\u001b[0m     )\n\u001b[1;32m    306\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommit(t, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m    307\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/langgraph/pregel/retry.py:127\u001b[0m, in \u001b[0;36marun_with_retry\u001b[0;34m(task, retry_policies, stream, configurable)\u001b[0m\n\u001b[1;32m    125\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m    126\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 127\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m task\u001b[38;5;241m.\u001b[39mproc\u001b[38;5;241m.\u001b[39mainvoke(task\u001b[38;5;241m.\u001b[39minput, config)\n\u001b[1;32m    128\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ParentCommand \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[1;32m    129\u001b[0m     ns: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m=\u001b[39m config[CONF][CONFIG_KEY_CHECKPOINT_NS]\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/langgraph/utils/runnable.py:675\u001b[0m, in \u001b[0;36mRunnableSeq.ainvoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m    671\u001b[0m             \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m asyncio\u001b[38;5;241m.\u001b[39mcreate_task(\n\u001b[1;32m    672\u001b[0m                 step\u001b[38;5;241m.\u001b[39mainvoke(\u001b[38;5;28minput\u001b[39m, config, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs), context\u001b[38;5;241m=\u001b[39mcontext\n\u001b[1;32m    673\u001b[0m             )\n\u001b[1;32m    674\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 675\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m step\u001b[38;5;241m.\u001b[39mainvoke(\u001b[38;5;28minput\u001b[39m, config, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    676\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    677\u001b[0m     \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m step\u001b[38;5;241m.\u001b[39mainvoke(\u001b[38;5;28minput\u001b[39m, config)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/langgraph/utils/runnable.py:439\u001b[0m, in \u001b[0;36mRunnableCallable.ainvoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m    437\u001b[0m         \u001b[38;5;28;01mawait\u001b[39;00m run_manager\u001b[38;5;241m.\u001b[39mon_chain_end(ret)\n\u001b[1;32m    438\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 439\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mafunc(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    440\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrecurse \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(ret, Runnable):\n\u001b[1;32m    441\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m ret\u001b[38;5;241m.\u001b[39mainvoke(\u001b[38;5;28minput\u001b[39m, config)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/open_deep_research/graph.py:123\u001b[0m, in \u001b[0;36mgenerate_report_plan\u001b[0;34m(state, config)\u001b[0m\n\u001b[1;32m    121\u001b[0m \u001b[38;5;66;03m# Generate the report sections\u001b[39;00m\n\u001b[1;32m    122\u001b[0m structured_llm \u001b[38;5;241m=\u001b[39m planner_llm\u001b[38;5;241m.\u001b[39mwith_structured_output(Sections)\n\u001b[0;32m--> 123\u001b[0m report_sections \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m structured_llm\u001b[38;5;241m.\u001b[39mainvoke([SystemMessage(content\u001b[38;5;241m=\u001b[39msystem_instructions_sections),\n\u001b[1;32m    124\u001b[0m                                          HumanMessage(content\u001b[38;5;241m=\u001b[39mplanner_message)])\n\u001b[1;32m    126\u001b[0m \u001b[38;5;66;03m# Get sections\u001b[39;00m\n\u001b[1;32m    127\u001b[0m sections \u001b[38;5;241m=\u001b[39m report_sections\u001b[38;5;241m.\u001b[39msections\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/langchain_core/runnables/base.py:3075\u001b[0m, in \u001b[0;36mRunnableSequence.ainvoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m   3073\u001b[0m             \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   3074\u001b[0m                 part \u001b[38;5;241m=\u001b[39m functools\u001b[38;5;241m.\u001b[39mpartial(step\u001b[38;5;241m.\u001b[39mainvoke, \u001b[38;5;28minput\u001b[39m, config)\n\u001b[0;32m-> 3075\u001b[0m             \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m coro_with_context(part(), context, create_task\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m   3076\u001b[0m     \u001b[38;5;66;03m# finish the root run\u001b[39;00m\n\u001b[1;32m   3077\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/langchain_core/runnables/base.py:5429\u001b[0m, in \u001b[0;36mRunnableBindingBase.ainvoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m   5422\u001b[0m \u001b[38;5;129m@override\u001b[39m\n\u001b[1;32m   5423\u001b[0m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mainvoke\u001b[39m(\n\u001b[1;32m   5424\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   5427\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Optional[Any],\n\u001b[1;32m   5428\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Output:\n\u001b[0;32m-> 5429\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbound\u001b[38;5;241m.\u001b[39mainvoke(\n\u001b[1;32m   5430\u001b[0m         \u001b[38;5;28minput\u001b[39m,\n\u001b[1;32m   5431\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_merge_configs(config),\n\u001b[1;32m   5432\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m{\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkwargs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs},\n\u001b[1;32m   5433\u001b[0m     )\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/langchain_core/language_models/chat_models.py:390\u001b[0m, in \u001b[0;36mBaseChatModel.ainvoke\u001b[0;34m(self, input, config, stop, **kwargs)\u001b[0m\n\u001b[1;32m    380\u001b[0m \u001b[38;5;129m@override\u001b[39m\n\u001b[1;32m    381\u001b[0m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mainvoke\u001b[39m(\n\u001b[1;32m    382\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    387\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[1;32m    388\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m BaseMessage:\n\u001b[1;32m    389\u001b[0m     config \u001b[38;5;241m=\u001b[39m ensure_config(config)\n\u001b[0;32m--> 390\u001b[0m     llm_result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39magenerate_prompt(\n\u001b[1;32m    391\u001b[0m         [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_convert_input(\u001b[38;5;28minput\u001b[39m)],\n\u001b[1;32m    392\u001b[0m         stop\u001b[38;5;241m=\u001b[39mstop,\n\u001b[1;32m    393\u001b[0m         callbacks\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcallbacks\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m    394\u001b[0m         tags\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtags\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m    395\u001b[0m         metadata\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetadata\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m    396\u001b[0m         run_name\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_name\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m    397\u001b[0m         run_id\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_id\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[1;32m    398\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m    399\u001b[0m     )\n\u001b[1;32m    400\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mChatGeneration\u001b[39m\u001b[38;5;124m\"\u001b[39m, llm_result\u001b[38;5;241m.\u001b[39mgenerations[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m0\u001b[39m])\u001b[38;5;241m.\u001b[39mmessage\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/langchain_core/language_models/chat_models.py:948\u001b[0m, in \u001b[0;36mBaseChatModel.agenerate_prompt\u001b[0;34m(self, prompts, stop, callbacks, **kwargs)\u001b[0m\n\u001b[1;32m    939\u001b[0m \u001b[38;5;129m@override\u001b[39m\n\u001b[1;32m    940\u001b[0m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21magenerate_prompt\u001b[39m(\n\u001b[1;32m    941\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    945\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[1;32m    946\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m LLMResult:\n\u001b[1;32m    947\u001b[0m     prompt_messages \u001b[38;5;241m=\u001b[39m [p\u001b[38;5;241m.\u001b[39mto_messages() \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m prompts]\n\u001b[0;32m--> 948\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39magenerate(\n\u001b[1;32m    949\u001b[0m         prompt_messages, stop\u001b[38;5;241m=\u001b[39mstop, callbacks\u001b[38;5;241m=\u001b[39mcallbacks, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[1;32m    950\u001b[0m     )\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/langchain_core/language_models/chat_models.py:906\u001b[0m, in \u001b[0;36mBaseChatModel.agenerate\u001b[0;34m(self, messages, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001b[0m\n\u001b[1;32m    893\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m run_managers:\n\u001b[1;32m    894\u001b[0m         \u001b[38;5;28;01mawait\u001b[39;00m asyncio\u001b[38;5;241m.\u001b[39mgather(\n\u001b[1;32m    895\u001b[0m             \u001b[38;5;241m*\u001b[39m[\n\u001b[1;32m    896\u001b[0m                 run_manager\u001b[38;5;241m.\u001b[39mon_llm_end(\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    904\u001b[0m             ]\n\u001b[1;32m    905\u001b[0m         )\n\u001b[0;32m--> 906\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exceptions[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    907\u001b[0m flattened_outputs \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    908\u001b[0m     LLMResult(generations\u001b[38;5;241m=\u001b[39m[res\u001b[38;5;241m.\u001b[39mgenerations], llm_output\u001b[38;5;241m=\u001b[39mres\u001b[38;5;241m.\u001b[39mllm_output)  \u001b[38;5;66;03m# type: ignore[list-item, union-attr]\u001b[39;00m\n\u001b[1;32m    909\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m res \u001b[38;5;129;01min\u001b[39;00m results\n\u001b[1;32m    910\u001b[0m ]\n\u001b[1;32m    911\u001b[0m llm_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_combine_llm_outputs([res\u001b[38;5;241m.\u001b[39mllm_output \u001b[38;5;28;01mfor\u001b[39;00m res \u001b[38;5;129;01min\u001b[39;00m results])  \u001b[38;5;66;03m# type: ignore[union-attr]\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/langchain_core/language_models/chat_models.py:1074\u001b[0m, in \u001b[0;36mBaseChatModel._agenerate_with_cache\u001b[0;34m(self, messages, stop, run_manager, **kwargs)\u001b[0m\n\u001b[1;32m   1072\u001b[0m     result \u001b[38;5;241m=\u001b[39m generate_from_stream(\u001b[38;5;28miter\u001b[39m(chunks))\n\u001b[1;32m   1073\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m inspect\u001b[38;5;241m.\u001b[39msignature(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_agenerate)\u001b[38;5;241m.\u001b[39mparameters\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_manager\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m-> 1074\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_agenerate(\n\u001b[1;32m   1075\u001b[0m         messages, stop\u001b[38;5;241m=\u001b[39mstop, run_manager\u001b[38;5;241m=\u001b[39mrun_manager, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[1;32m   1076\u001b[0m     )\n\u001b[1;32m   1077\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1078\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_agenerate(messages, stop\u001b[38;5;241m=\u001b[39mstop, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/langchain_groq/chat_models.py:519\u001b[0m, in \u001b[0;36mChatGroq._agenerate\u001b[0;34m(self, messages, stop, run_manager, **kwargs)\u001b[0m\n\u001b[1;32m    514\u001b[0m message_dicts, params \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_create_message_dicts(messages, stop)\n\u001b[1;32m    515\u001b[0m params \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    516\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams,\n\u001b[1;32m    517\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m    518\u001b[0m }\n\u001b[0;32m--> 519\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39masync_client\u001b[38;5;241m.\u001b[39mcreate(messages\u001b[38;5;241m=\u001b[39mmessage_dicts, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams)\n\u001b[1;32m    520\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_create_chat_result(response)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/groq/resources/chat/completions.py:649\u001b[0m, in \u001b[0;36mAsyncCompletions.create\u001b[0;34m(self, messages, model, frequency_penalty, function_call, functions, logit_bias, logprobs, max_completion_tokens, max_tokens, n, parallel_tool_calls, presence_penalty, reasoning_format, response_format, seed, service_tier, stop, stream, temperature, tool_choice, tools, top_logprobs, top_p, user, extra_headers, extra_query, extra_body, timeout)\u001b[0m\n\u001b[1;32m    493\u001b[0m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mcreate\u001b[39m(\n\u001b[1;32m    494\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    495\u001b[0m     \u001b[38;5;241m*\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    525\u001b[0m     timeout: \u001b[38;5;28mfloat\u001b[39m \u001b[38;5;241m|\u001b[39m httpx\u001b[38;5;241m.\u001b[39mTimeout \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m|\u001b[39m NotGiven \u001b[38;5;241m=\u001b[39m NOT_GIVEN,\n\u001b[1;32m    526\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ChatCompletion \u001b[38;5;241m|\u001b[39m AsyncStream[ChatCompletionChunk]:\n\u001b[1;32m    527\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    528\u001b[0m \u001b[38;5;124;03m    Creates a model response for the given chat conversation.\u001b[39;00m\n\u001b[1;32m    529\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    647\u001b[0m \u001b[38;5;124;03m      timeout: Override the client-level default timeout for this request, in seconds\u001b[39;00m\n\u001b[1;32m    648\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 649\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_post(\n\u001b[1;32m    650\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/openai/v1/chat/completions\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    651\u001b[0m         body\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mawait\u001b[39;00m async_maybe_transform(\n\u001b[1;32m    652\u001b[0m             {\n\u001b[1;32m    653\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m: messages,\n\u001b[1;32m    654\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m: model,\n\u001b[1;32m    655\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfrequency_penalty\u001b[39m\u001b[38;5;124m\"\u001b[39m: frequency_penalty,\n\u001b[1;32m    656\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfunction_call\u001b[39m\u001b[38;5;124m\"\u001b[39m: function_call,\n\u001b[1;32m    657\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfunctions\u001b[39m\u001b[38;5;124m\"\u001b[39m: functions,\n\u001b[1;32m    658\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlogit_bias\u001b[39m\u001b[38;5;124m\"\u001b[39m: logit_bias,\n\u001b[1;32m    659\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlogprobs\u001b[39m\u001b[38;5;124m\"\u001b[39m: logprobs,\n\u001b[1;32m    660\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmax_completion_tokens\u001b[39m\u001b[38;5;124m\"\u001b[39m: max_completion_tokens,\n\u001b[1;32m    661\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmax_tokens\u001b[39m\u001b[38;5;124m\"\u001b[39m: max_tokens,\n\u001b[1;32m    662\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mn\u001b[39m\u001b[38;5;124m\"\u001b[39m: n,\n\u001b[1;32m    663\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparallel_tool_calls\u001b[39m\u001b[38;5;124m\"\u001b[39m: parallel_tool_calls,\n\u001b[1;32m    664\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpresence_penalty\u001b[39m\u001b[38;5;124m\"\u001b[39m: presence_penalty,\n\u001b[1;32m    665\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreasoning_format\u001b[39m\u001b[38;5;124m\"\u001b[39m: reasoning_format,\n\u001b[1;32m    666\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresponse_format\u001b[39m\u001b[38;5;124m\"\u001b[39m: response_format,\n\u001b[1;32m    667\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mseed\u001b[39m\u001b[38;5;124m\"\u001b[39m: seed,\n\u001b[1;32m    668\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mservice_tier\u001b[39m\u001b[38;5;124m\"\u001b[39m: service_tier,\n\u001b[1;32m    669\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstop\u001b[39m\u001b[38;5;124m\"\u001b[39m: stop,\n\u001b[1;32m    670\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstream\u001b[39m\u001b[38;5;124m\"\u001b[39m: stream,\n\u001b[1;32m    671\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtemperature\u001b[39m\u001b[38;5;124m\"\u001b[39m: temperature,\n\u001b[1;32m    672\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtool_choice\u001b[39m\u001b[38;5;124m\"\u001b[39m: tool_choice,\n\u001b[1;32m    673\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtools\u001b[39m\u001b[38;5;124m\"\u001b[39m: tools,\n\u001b[1;32m    674\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtop_logprobs\u001b[39m\u001b[38;5;124m\"\u001b[39m: top_logprobs,\n\u001b[1;32m    675\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtop_p\u001b[39m\u001b[38;5;124m\"\u001b[39m: top_p,\n\u001b[1;32m    676\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muser\u001b[39m\u001b[38;5;124m\"\u001b[39m: user,\n\u001b[1;32m    677\u001b[0m             },\n\u001b[1;32m    678\u001b[0m             completion_create_params\u001b[38;5;241m.\u001b[39mCompletionCreateParams,\n\u001b[1;32m    679\u001b[0m         ),\n\u001b[1;32m    680\u001b[0m         options\u001b[38;5;241m=\u001b[39mmake_request_options(\n\u001b[1;32m    681\u001b[0m             extra_headers\u001b[38;5;241m=\u001b[39mextra_headers, extra_query\u001b[38;5;241m=\u001b[39mextra_query, extra_body\u001b[38;5;241m=\u001b[39mextra_body, timeout\u001b[38;5;241m=\u001b[39mtimeout\n\u001b[1;32m    682\u001b[0m         ),\n\u001b[1;32m    683\u001b[0m         cast_to\u001b[38;5;241m=\u001b[39mChatCompletion,\n\u001b[1;32m    684\u001b[0m         stream\u001b[38;5;241m=\u001b[39mstream \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    685\u001b[0m         stream_cls\u001b[38;5;241m=\u001b[39mAsyncStream[ChatCompletionChunk],\n\u001b[1;32m    686\u001b[0m     )\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/groq/_base_client.py:1736\u001b[0m, in \u001b[0;36mAsyncAPIClient.post\u001b[0;34m(self, path, cast_to, body, files, options, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1722\u001b[0m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mpost\u001b[39m(\n\u001b[1;32m   1723\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   1724\u001b[0m     path: \u001b[38;5;28mstr\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1731\u001b[0m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_AsyncStreamT] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1732\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ResponseT \u001b[38;5;241m|\u001b[39m _AsyncStreamT:\n\u001b[1;32m   1733\u001b[0m     opts \u001b[38;5;241m=\u001b[39m FinalRequestOptions\u001b[38;5;241m.\u001b[39mconstruct(\n\u001b[1;32m   1734\u001b[0m         method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpost\u001b[39m\u001b[38;5;124m\"\u001b[39m, url\u001b[38;5;241m=\u001b[39mpath, json_data\u001b[38;5;241m=\u001b[39mbody, files\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mawait\u001b[39;00m async_to_httpx_files(files), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions\n\u001b[1;32m   1735\u001b[0m     )\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrequest(cast_to, opts, stream\u001b[38;5;241m=\u001b[39mstream, stream_cls\u001b[38;5;241m=\u001b[39mstream_cls)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/groq/_base_client.py:1444\u001b[0m, in \u001b[0;36mAsyncAPIClient.request\u001b[0;34m(self, cast_to, options, stream, stream_cls, remaining_retries)\u001b[0m\n\u001b[1;32m   1441\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1442\u001b[0m     retries_taken \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m-> 1444\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_request(\n\u001b[1;32m   1445\u001b[0m     cast_to\u001b[38;5;241m=\u001b[39mcast_to,\n\u001b[1;32m   1446\u001b[0m     options\u001b[38;5;241m=\u001b[39moptions,\n\u001b[1;32m   1447\u001b[0m     stream\u001b[38;5;241m=\u001b[39mstream,\n\u001b[1;32m   1448\u001b[0m     stream_cls\u001b[38;5;241m=\u001b[39mstream_cls,\n\u001b[1;32m   1449\u001b[0m     retries_taken\u001b[38;5;241m=\u001b[39mretries_taken,\n\u001b[1;32m   1450\u001b[0m )\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/groq/_base_client.py:1545\u001b[0m, in \u001b[0;36mAsyncAPIClient._request\u001b[0;34m(self, cast_to, options, stream, stream_cls, retries_taken)\u001b[0m\n\u001b[1;32m   1542\u001b[0m         \u001b[38;5;28;01mawait\u001b[39;00m err\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39maread()\n\u001b[1;32m   1544\u001b[0m     log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRe-raising status error\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m-> 1545\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_status_error_from_response(err\u001b[38;5;241m.\u001b[39mresponse) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1547\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_response(\n\u001b[1;32m   1548\u001b[0m     cast_to\u001b[38;5;241m=\u001b[39mcast_to,\n\u001b[1;32m   1549\u001b[0m     options\u001b[38;5;241m=\u001b[39moptions,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1553\u001b[0m     retries_taken\u001b[38;5;241m=\u001b[39mretries_taken,\n\u001b[1;32m   1554\u001b[0m )\n",
      "\u001b[0;31mAPIStatusError\u001b[0m: Error code: 413 - {'error': {'message': 'Request too large for model `llama-3.3-70b-versatile` in organization `org_01jvm4g19ye79b5d2ax2wmsvac` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Requested 30287, please reduce your message size and try again. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}"
     ]
    }
   ],
   "source": [
    "import uuid \n",
    "from IPython.display import Markdown\n",
    "\n",
    "REPORT_STRUCTURE = \"\"\"Use this structure to create a report on the user-provided topic:\n",
    "\n",
    "1. Introduction (no research needed)\n",
    "   - Brief overview of the topic area\n",
    "\n",
    "2. Main Body Sections:\n",
    "   - Each section should focus on a sub-topic of the user-provided topic\n",
    "   \n",
    "3. Conclusion\n",
    "   - Aim for 1 structural element (either a list of table) that distills the main body sections \n",
    "   - Provide a concise summary of the report\"\"\"\n",
    "\n",
    "# Claude 3.7 Sonnet for planning with perplexity search\n",
    "# thread = {\"configurable\": {\"thread_id\": str(uuid.uuid4()),\n",
    "#                            \"search_api\": \"perplexity\",\n",
    "#                            \"planner_provider\": \"anthropic\",\n",
    "#                            \"planner_model\": \"claude-3-7-sonnet-latest\",\n",
    "#                            \"writer_provider\": \"anthropic\",\n",
    "#                            \"writer_model\": \"claude-3-5-sonnet-latest\",\n",
    "#                            \"max_search_depth\": 2,\n",
    "#                            \"report_structure\": REPORT_STRUCTURE,\n",
    "#                            }}\n",
    "\n",
    "# DeepSeek-R1-Distill-Llama-70B for planning and llama-3.3-70b-versatile for writing\n",
    "thread = {\"configurable\": {\"thread_id\": str(uuid.uuid4()),\n",
    "                           # \"search_api\": \"tavily\",\n",
    "                           \"planner_provider\": \"groq\",\n",
    "                           \"planner_model\": \"llama-3.3-70b-versatile\",\n",
    "                           \"writer_provider\": \"groq\",\n",
    "                           \"writer_model\": \"llama-3.3-70b-versatile\",\n",
    "                           \"report_structure\": REPORT_STRUCTURE,\n",
    "                           \"max_search_depth\": 1,}\n",
    "                           }\n",
    "\n",
    "# # Fast config (less search depth) with o3-mini for planning and Claude 3.5 Sonnet for writing\n",
    "# thread = {\"configurable\": {\"thread_id\": str(uuid.uuid4()),\n",
    "#                            \"search_api\": \"tavily\",\n",
    "#                            \"planner_provider\": \"openai\",\n",
    "#                            \"planner_model\": \"o3-mini\",\n",
    "#                            \"writer_provider\": \"anthropic\",\n",
    "#                            \"writer_model\": \"claude-3-5-sonnet-latest\",\n",
    "#                            \"max_search_depth\": 1,\n",
    "#                            \"report_structure\": REPORT_STRUCTURE,\n",
    "#                            }}\n",
    "\n",
    "# Create a topic  (should not hardcode for us) (becomes input)\n",
    "topic = input(\"input research topic here\")\n",
    "#find whether in feedback or not\n",
    "feedback_status = 0\n",
    "end_status = 0\n",
    "# Run the graph until the interruption\n",
    "async for event in graph.astream({\"topic\":topic}, thread, stream_mode=\"updates\"):\n",
    "   if '__interrupt__' in event:\n",
    "      interrupt_value = event['__interrupt__'][0].value\n",
    "      display(Markdown(interrupt_value))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Please provide feedback on the following report plan. \n",
       "                        \n",
       "\n",
       "Section: Introduction\n",
       "Description: Provides a brief overview of the AI inference market, its relevance, and introduces the three key players: Fireworks, Together.ai, and Groq.\n",
       "Research needed: No\n",
       "\n",
       "\n",
       "Section: Fireworks AI Overview\n",
       "Description: Covers Fireworks AI’s offerings in the inference market, including key performance metrics, product features, model quality, speed, and latency. Emphasizes revenue estimates (ARR) as part of its market positioning.\n",
       "Research needed: Yes\n",
       "\n",
       "\n",
       "Section: Together.ai Overview\n",
       "Description: Explores Together.ai’s role within the AI inference space. Discusses product features, integration details, user reviews, and performance metrics along with ARR revenue estimates.\n",
       "Research needed: Yes\n",
       "\n",
       "\n",
       "Section: Groq AI Overview\n",
       "Description: Examines Groq’s AI inference solutions with a focus on benchmark performance, inference speed, and cost efficiency. Includes an analysis of ARR revenue and how its technical performance shapes its market position.\n",
       "Research needed: Yes\n",
       "\n",
       "\n",
       "Section: Market Comparison and Trends\n",
       "Description: Provides a comparative analysis highlighting the strengths, weaknesses, and differentiating factors of Fireworks, Together.ai, and Groq. Discusses trends like cost, performance metrics, and revenue (ARR) estimates.\n",
       "Research needed: Yes\n",
       "\n",
       "\n",
       "Section: Conclusion\n",
       "Description: Summarizes key findings from the individual sections and the comparative analysis. Offers a concise distillation of the market landscape using a summary table or list to highlight major points including ARR insights.\n",
       "Research needed: No\n",
       "\n",
       "\n",
       "                        \n",
       "Does the report plan meet your needs?\n",
       "Pass 'true' to approve the report plan.\n",
       "Or, provide feedback to regenerate the report plan:"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Pass feedback to update the report plan   (part after resume shouldnt be hardcoded either, that is the feedback) (to figure: make sure  bot knows we are in feedback loop)\n",
    "While feedback_status <= 5:\n",
    "    feedback_status += 1 \n",
    "    feedback = input(\"input feedback\")\n",
    "    if feedback == \"nil\":\n",
    "        break \n",
    "    async for event in graph.astream(Command(resume=feedback), thread, stream_mode=\"updates\"):\n",
    "        if '__interrupt__' in event:\n",
    "            interrupt_value = event['__interrupt__'][0].value\n",
    "            display(Markdown(interrupt_value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'human_feedback': None}\n",
      "\n",
      "\n",
      "{'build_section_with_web_research': {'completed_sections': [Section(name='Groq AI Overview', description='Examines Groq’s AI inference solutions with a focus on benchmark performance, inference speed, and cost efficiency. Includes an analysis of ARR revenue and how its technical performance shapes its market position.', research=True, content=\"## Groq AI Overview\\n\\nGroq has emerged as a significant player in the AI inference market with its innovative Language Processing Unit (LPU) technology. Independent benchmarks from ArtificialAnalysis.ai demonstrate Groq's impressive performance, with their Llama 2 Chat (70B) API achieving 241 tokens per second - more than double the speed of competing providers [1]. Their total response time for 100 output tokens is just 0.8 seconds, positioning them as a leader in inference speed [2].\\n\\nThe company's core technology, the Tensor Streaming Processor (TSP), delivers 500-700 tokens per second on large language models, representing a 5-10x improvement over Nvidia's latest data center GPUs [3]. This performance advantage has positioned Groq as a compelling alternative in the inference market, particularly for startups seeking cost-effective solutions [4].\\n\\nWith approximately 300 employees, 60% of whom are software engineers, Groq has evolved beyond hardware to become a comprehensive AI solutions provider [5]. The company is strategically positioned to capture a share of the growing inference chip market, which is projected to reach $48 billion by 2027 [6].\\n\\n### Sources\\n[1] https://groq.com/artificialanalysis-ai-llm-benchmark-doubles-axis-to-fit-new-groq-lpu-inference-engine-performance-results/\\n[2] https://groq.com/inference/\\n[3] https://sacra.com/c/groq/\\n[4] https://venturebeat.com/ai/ai-chip-race-groq-ceo-takes-on-nvidia-claims-most-startups-will-use-speedy-lpus-by-end-of-2024/\\n[5] https://www.businessinsider.com/groq-nvidia-software-advantage-cuda-moat-challenge-inference-2024-12?op=1\\n[6] https://generativeaitech.substack.com/p/groq-and-its-impact-on-ai-inference\")]}}\n",
      "\n",
      "\n",
      "{'build_section_with_web_research': {'completed_sections': [Section(name='Market Comparison and Trends', description='Provides a comparative analysis highlighting the strengths, weaknesses, and differentiating factors of Fireworks, Together.ai, and Groq. Discusses trends like cost, performance metrics, and revenue (ARR) estimates.', research=True, content=\"## Market Comparison and Trends\\n\\nThe AI inference market shows distinct positioning among key players Fireworks, Together.ai, and Groq. Fireworks AI differentiates itself through superior speed, leveraging its proprietary FireAttention inference engine for text, image, and audio processing, while maintaining HIPAA and SOC2 compliance for data privacy [1]. Together.ai has demonstrated remarkable growth, reaching an estimated $130M in annualized recurring revenue (ARR) in 2024, representing a 400% year-over-year increase [2].\\n\\nBoth Fireworks and Together.ai focus on providing high-quality open-source models that can compete with proprietary alternatives [1]. Pricing structures vary across providers, with model costs ranging from $0.20 to $3.00 per million tokens for different model sizes and capabilities [3]. Together.ai's business model benefits from GPU price commoditization, allowing them to maintain competitive token pricing while focusing on developer experience and reliable inference across diverse open-source models [2].\\n\\nGroq distinguishes itself by offering quick access to various open-source AI models from major providers like Google, Meta, OpenAI, and Mistral through the OpenRouter API platform [4]. The market shows a trend toward comprehensive platform offerings, with providers competing on factors such as model variety, inference speed, and specialized features for different use cases.\\n\\n### Sources\\n[1] Top 10 AI Inference Platforms in 2025: Comparing LLM API Providers: https://www.helicone.ai/blog/llm-api-providers\\n[2] Together AI revenue, valuation & growth rate | Sacra: https://sacra.com/c/together-ai/\\n[3] Models Leaderboard : Comparison of AI Models & API Providers - Groq AI: https://groq-ai.com/models/\\n[4] Pricing: Compare Groq API Pricing With Other API Providers: https://groq-ai.com/pricing/\")]}}\n",
      "\n",
      "\n",
      "{'build_section_with_web_research': {'completed_sections': [Section(name='Together.ai Overview', description='Explores Together.ai’s role within the AI inference space. Discusses product features, integration details, user reviews, and performance metrics along with ARR revenue estimates.', research=True, content=\"## Together.ai Overview\\n\\nTogether.ai is a comprehensive AI acceleration platform that has quickly emerged as a significant player in the AI inference space since its founding in 2022 [1]. The platform enables developers to access over 200 AI models, offering high-performance inference capabilities with optimized infrastructure [2].\\n\\nThe company's Inference Engine, built on NVIDIA Tensor Core GPUs, delivers impressive performance metrics, achieving 117 tokens per second on Llama-2-70B-Chat models [3]. Their model offerings include high-quality options like Llama 3.3 70B Turbo and Llama 3.1 405B Turbo, with some models achieving sub-100ms latency [4].\\n\\nTogether.ai has demonstrated remarkable growth, with estimates suggesting $130M in annualized recurring revenue (ARR) in 2024, representing a 400% year-over-year increase [5]. The platform has received positive user feedback, maintaining a 4.8/5.0 rating based on 162 user reviews [6].\\n\\nThe company differentiates itself through competitive pricing and technical innovations, incorporating advanced features like token caching, load balancing, and model quantization [2]. Users particularly praise the platform's straightforward API, reliable performance, and competitive pricing compared to alternatives [7].\\n\\n### Sources\\n[1] https://siliconvalleyjournals.com/company/together-ai/\\n[2] https://www.keywordsai.co/blog/top-10-llm-api-providers\\n[3] https://www.together.ai/blog/together-inference-engine-v1\\n[4] https://artificialanalysis.ai/providers/togetherai\\n[5] https://sacra.com/c/together-ai/\\n[6] https://www.featuredcustomers.com/vendor/together-ai\\n[7] https://www.trustpilot.com/review/together.ai\")]}}\n",
      "\n",
      "\n",
      "{'build_section_with_web_research': {'completed_sections': [Section(name='Fireworks AI Overview', description='Covers Fireworks AI’s offerings in the inference market, including key performance metrics, product features, model quality, speed, and latency. Emphasizes revenue estimates (ARR) as part of its market positioning.', research=True, content='## Fireworks AI Overview\\n\\nFireworks AI has established itself as a significant player in the AI inference market, offering a comprehensive platform for deploying and managing AI models. The company provides access to various high-performance models, including Llama 3.1 405B and Qwen2.5 Coder 32B, which represent their highest quality offerings [1]. Their platform demonstrates impressive performance metrics, with some models achieving speeds up to 300 tokens per second for serverless deployments [2].\\n\\nThe company has gained substantial market traction, recently securing $52 million in Series B funding that values the company at $552 million [3]. With an annual revenue of $6 million and a team of 60 employees, Fireworks AI serves notable clients including DoorDash, Quora, and Upwork [4, 5].\\n\\nTheir platform differentiates itself through specialized features like FP8 quantization for large models and continuous batching capabilities [6]. Fireworks claims to offer approximately 3x faster speeds compared to competitors like Hugging Face TGI when using the same GPU configuration [2]. The company focuses on providing smaller, production-grade models that can be deployed privately and securely, rather than generic mega models [5].\\n\\n### Sources\\n[1] Fireworks: Models Intelligence, Performance & Price: https://artificialanalysis.ai/providers/fireworks\\n[2] Fireworks Platform Spring 2024 Updates: https://fireworks.ai/blog/spring-update-faster-models-dedicated-deployments-postpaid-pricing\\n[3] Fireworks AI Raises $52M in Series B Funding: https://siliconvalleyjournals.com/fireworks-ai-raises-52m-in-series-b-funding-to-expand-genai-inference-platform/\\n[4] Fireworks AI: Contact Details, Revenue, Funding: https://siliconvalleyjournals.com/company/fireworks-ai/\\n[5] Fireworks AI Valued at $552 Million After New Funding Round: https://www.pymnts.com/news/investment-tracker/2024/fireworks-ai-valued-552-million-dollars-after-new-funding-round/\\n[6] Inference performance - Fireworks AI Docs: https://docs.fireworks.ai/faq/models/inference/performance')]}}\n",
      "\n",
      "\n",
      "{'gather_completed_sections': {'report_sections_from_research': \"\\n============================================================\\nSection 1: Fireworks AI Overview\\n============================================================\\nDescription:\\nCovers Fireworks AI’s offerings in the inference market, including key performance metrics, product features, model quality, speed, and latency. Emphasizes revenue estimates (ARR) as part of its market positioning.\\nRequires Research: \\nTrue\\n\\nContent:\\n## Fireworks AI Overview\\n\\nFireworks AI has established itself as a significant player in the AI inference market, offering a comprehensive platform for deploying and managing AI models. The company provides access to various high-performance models, including Llama 3.1 405B and Qwen2.5 Coder 32B, which represent their highest quality offerings [1]. Their platform demonstrates impressive performance metrics, with some models achieving speeds up to 300 tokens per second for serverless deployments [2].\\n\\nThe company has gained substantial market traction, recently securing $52 million in Series B funding that values the company at $552 million [3]. With an annual revenue of $6 million and a team of 60 employees, Fireworks AI serves notable clients including DoorDash, Quora, and Upwork [4, 5].\\n\\nTheir platform differentiates itself through specialized features like FP8 quantization for large models and continuous batching capabilities [6]. Fireworks claims to offer approximately 3x faster speeds compared to competitors like Hugging Face TGI when using the same GPU configuration [2]. The company focuses on providing smaller, production-grade models that can be deployed privately and securely, rather than generic mega models [5].\\n\\n### Sources\\n[1] Fireworks: Models Intelligence, Performance & Price: https://artificialanalysis.ai/providers/fireworks\\n[2] Fireworks Platform Spring 2024 Updates: https://fireworks.ai/blog/spring-update-faster-models-dedicated-deployments-postpaid-pricing\\n[3] Fireworks AI Raises $52M in Series B Funding: https://siliconvalleyjournals.com/fireworks-ai-raises-52m-in-series-b-funding-to-expand-genai-inference-platform/\\n[4] Fireworks AI: Contact Details, Revenue, Funding: https://siliconvalleyjournals.com/company/fireworks-ai/\\n[5] Fireworks AI Valued at $552 Million After New Funding Round: https://www.pymnts.com/news/investment-tracker/2024/fireworks-ai-valued-552-million-dollars-after-new-funding-round/\\n[6] Inference performance - Fireworks AI Docs: https://docs.fireworks.ai/faq/models/inference/performance\\n\\n\\n============================================================\\nSection 2: Together.ai Overview\\n============================================================\\nDescription:\\nExplores Together.ai’s role within the AI inference space. Discusses product features, integration details, user reviews, and performance metrics along with ARR revenue estimates.\\nRequires Research: \\nTrue\\n\\nContent:\\n## Together.ai Overview\\n\\nTogether.ai is a comprehensive AI acceleration platform that has quickly emerged as a significant player in the AI inference space since its founding in 2022 [1]. The platform enables developers to access over 200 AI models, offering high-performance inference capabilities with optimized infrastructure [2].\\n\\nThe company's Inference Engine, built on NVIDIA Tensor Core GPUs, delivers impressive performance metrics, achieving 117 tokens per second on Llama-2-70B-Chat models [3]. Their model offerings include high-quality options like Llama 3.3 70B Turbo and Llama 3.1 405B Turbo, with some models achieving sub-100ms latency [4].\\n\\nTogether.ai has demonstrated remarkable growth, with estimates suggesting $130M in annualized recurring revenue (ARR) in 2024, representing a 400% year-over-year increase [5]. The platform has received positive user feedback, maintaining a 4.8/5.0 rating based on 162 user reviews [6].\\n\\nThe company differentiates itself through competitive pricing and technical innovations, incorporating advanced features like token caching, load balancing, and model quantization [2]. Users particularly praise the platform's straightforward API, reliable performance, and competitive pricing compared to alternatives [7].\\n\\n### Sources\\n[1] https://siliconvalleyjournals.com/company/together-ai/\\n[2] https://www.keywordsai.co/blog/top-10-llm-api-providers\\n[3] https://www.together.ai/blog/together-inference-engine-v1\\n[4] https://artificialanalysis.ai/providers/togetherai\\n[5] https://sacra.com/c/together-ai/\\n[6] https://www.featuredcustomers.com/vendor/together-ai\\n[7] https://www.trustpilot.com/review/together.ai\\n\\n\\n============================================================\\nSection 3: Groq AI Overview\\n============================================================\\nDescription:\\nExamines Groq’s AI inference solutions with a focus on benchmark performance, inference speed, and cost efficiency. Includes an analysis of ARR revenue and how its technical performance shapes its market position.\\nRequires Research: \\nTrue\\n\\nContent:\\n## Groq AI Overview\\n\\nGroq has emerged as a significant player in the AI inference market with its innovative Language Processing Unit (LPU) technology. Independent benchmarks from ArtificialAnalysis.ai demonstrate Groq's impressive performance, with their Llama 2 Chat (70B) API achieving 241 tokens per second - more than double the speed of competing providers [1]. Their total response time for 100 output tokens is just 0.8 seconds, positioning them as a leader in inference speed [2].\\n\\nThe company's core technology, the Tensor Streaming Processor (TSP), delivers 500-700 tokens per second on large language models, representing a 5-10x improvement over Nvidia's latest data center GPUs [3]. This performance advantage has positioned Groq as a compelling alternative in the inference market, particularly for startups seeking cost-effective solutions [4].\\n\\nWith approximately 300 employees, 60% of whom are software engineers, Groq has evolved beyond hardware to become a comprehensive AI solutions provider [5]. The company is strategically positioned to capture a share of the growing inference chip market, which is projected to reach $48 billion by 2027 [6].\\n\\n### Sources\\n[1] https://groq.com/artificialanalysis-ai-llm-benchmark-doubles-axis-to-fit-new-groq-lpu-inference-engine-performance-results/\\n[2] https://groq.com/inference/\\n[3] https://sacra.com/c/groq/\\n[4] https://venturebeat.com/ai/ai-chip-race-groq-ceo-takes-on-nvidia-claims-most-startups-will-use-speedy-lpus-by-end-of-2024/\\n[5] https://www.businessinsider.com/groq-nvidia-software-advantage-cuda-moat-challenge-inference-2024-12?op=1\\n[6] https://generativeaitech.substack.com/p/groq-and-its-impact-on-ai-inference\\n\\n\\n============================================================\\nSection 4: Market Comparison and Trends\\n============================================================\\nDescription:\\nProvides a comparative analysis highlighting the strengths, weaknesses, and differentiating factors of Fireworks, Together.ai, and Groq. Discusses trends like cost, performance metrics, and revenue (ARR) estimates.\\nRequires Research: \\nTrue\\n\\nContent:\\n## Market Comparison and Trends\\n\\nThe AI inference market shows distinct positioning among key players Fireworks, Together.ai, and Groq. Fireworks AI differentiates itself through superior speed, leveraging its proprietary FireAttention inference engine for text, image, and audio processing, while maintaining HIPAA and SOC2 compliance for data privacy [1]. Together.ai has demonstrated remarkable growth, reaching an estimated $130M in annualized recurring revenue (ARR) in 2024, representing a 400% year-over-year increase [2].\\n\\nBoth Fireworks and Together.ai focus on providing high-quality open-source models that can compete with proprietary alternatives [1]. Pricing structures vary across providers, with model costs ranging from $0.20 to $3.00 per million tokens for different model sizes and capabilities [3]. Together.ai's business model benefits from GPU price commoditization, allowing them to maintain competitive token pricing while focusing on developer experience and reliable inference across diverse open-source models [2].\\n\\nGroq distinguishes itself by offering quick access to various open-source AI models from major providers like Google, Meta, OpenAI, and Mistral through the OpenRouter API platform [4]. The market shows a trend toward comprehensive platform offerings, with providers competing on factors such as model variety, inference speed, and specialized features for different use cases.\\n\\n### Sources\\n[1] Top 10 AI Inference Platforms in 2025: Comparing LLM API Providers: https://www.helicone.ai/blog/llm-api-providers\\n[2] Together AI revenue, valuation & growth rate | Sacra: https://sacra.com/c/together-ai/\\n[3] Models Leaderboard : Comparison of AI Models & API Providers - Groq AI: https://groq-ai.com/models/\\n[4] Pricing: Compare Groq API Pricing With Other API Providers: https://groq-ai.com/pricing/\\n\\n\"}}\n",
      "\n",
      "\n",
      "{'write_final_sections': {'completed_sections': [Section(name='Introduction', description='Provides a brief overview of the AI inference market, its relevance, and introduces the three key players: Fireworks, Together.ai, and Groq.', research=False, content=\"# AI Inference Market: Analysis of Fireworks, Together.ai, and Groq\\n\\nThe AI inference market is experiencing rapid evolution as companies compete to provide faster, more efficient solutions for deploying and managing AI models. This analysis examines three key players reshaping the landscape: Fireworks, Together.ai, and Groq. Each brings distinct advantages - Fireworks with its specialized features and security focus, Together.ai with its comprehensive platform and impressive growth trajectory, and Groq with its groundbreaking Language Processing Unit technology. As organizations increasingly rely on AI inference capabilities, understanding these providers' strengths and market positions becomes crucial for making informed deployment decisions.\")]}}\n",
      "\n",
      "\n",
      "{'write_final_sections': {'completed_sections': [Section(name='Conclusion', description='Summarizes key findings from the individual sections and the comparative analysis. Offers a concise distillation of the market landscape using a summary table or list to highlight major points including ARR insights.', research=False, content='## Conclusion\\n\\nThe AI inference market shows clear differentiation among key players, with each provider carving out unique value propositions. Together.ai leads in revenue growth with $130M ARR, while Fireworks AI demonstrates strong potential with its recent $552M valuation. Groq distinguishes itself through superior inference speeds, achieving up to 700 tokens per second with its LPU technology.\\n\\n| Metric | Fireworks | Together.ai | Groq |\\n|--------|-----------|-------------|------|\\n| ARR | $6M | $130M | Not disclosed |\\n| Speed (tokens/sec) | Up to 300 | Up to 117 | 500-700 |\\n| Key Differentiator | FP8 quantization | 200+ model access | LPU technology |\\n| Notable Feature | 3x faster than competitors | Token caching | Sub-second response |\\n| Target Market | Enterprise security | Developer platforms | Startup solutions |\\n\\nThe market trends indicate a shift toward comprehensive platform offerings that balance speed, cost-efficiency, and model variety. As the inference chip market approaches $48B by 2027, providers focusing on specialized hardware solutions and optimized infrastructure will likely gain competitive advantages. Success will depend on maintaining the delicate balance between performance, pricing, and platform features while addressing growing enterprise demands for security and reliability.')]}}\n",
      "\n",
      "\n",
      "{'compile_final_report': {'final_report': \"# AI Inference Market: Analysis of Fireworks, Together.ai, and Groq\\n\\nThe AI inference market is experiencing rapid evolution as companies compete to provide faster, more efficient solutions for deploying and managing AI models. This analysis examines three key players reshaping the landscape: Fireworks, Together.ai, and Groq. Each brings distinct advantages - Fireworks with its specialized features and security focus, Together.ai with its comprehensive platform and impressive growth trajectory, and Groq with its groundbreaking Language Processing Unit technology. As organizations increasingly rely on AI inference capabilities, understanding these providers' strengths and market positions becomes crucial for making informed deployment decisions.\\n\\n## Fireworks AI Overview\\n\\nFireworks AI has established itself as a significant player in the AI inference market, offering a comprehensive platform for deploying and managing AI models. The company provides access to various high-performance models, including Llama 3.1 405B and Qwen2.5 Coder 32B, which represent their highest quality offerings [1]. Their platform demonstrates impressive performance metrics, with some models achieving speeds up to 300 tokens per second for serverless deployments [2].\\n\\nThe company has gained substantial market traction, recently securing $52 million in Series B funding that values the company at $552 million [3]. With an annual revenue of $6 million and a team of 60 employees, Fireworks AI serves notable clients including DoorDash, Quora, and Upwork [4, 5].\\n\\nTheir platform differentiates itself through specialized features like FP8 quantization for large models and continuous batching capabilities [6]. Fireworks claims to offer approximately 3x faster speeds compared to competitors like Hugging Face TGI when using the same GPU configuration [2]. The company focuses on providing smaller, production-grade models that can be deployed privately and securely, rather than generic mega models [5].\\n\\n### Sources\\n[1] Fireworks: Models Intelligence, Performance & Price: https://artificialanalysis.ai/providers/fireworks\\n[2] Fireworks Platform Spring 2024 Updates: https://fireworks.ai/blog/spring-update-faster-models-dedicated-deployments-postpaid-pricing\\n[3] Fireworks AI Raises $52M in Series B Funding: https://siliconvalleyjournals.com/fireworks-ai-raises-52m-in-series-b-funding-to-expand-genai-inference-platform/\\n[4] Fireworks AI: Contact Details, Revenue, Funding: https://siliconvalleyjournals.com/company/fireworks-ai/\\n[5] Fireworks AI Valued at $552 Million After New Funding Round: https://www.pymnts.com/news/investment-tracker/2024/fireworks-ai-valued-552-million-dollars-after-new-funding-round/\\n[6] Inference performance - Fireworks AI Docs: https://docs.fireworks.ai/faq/models/inference/performance\\n\\n## Together.ai Overview\\n\\nTogether.ai is a comprehensive AI acceleration platform that has quickly emerged as a significant player in the AI inference space since its founding in 2022 [1]. The platform enables developers to access over 200 AI models, offering high-performance inference capabilities with optimized infrastructure [2].\\n\\nThe company's Inference Engine, built on NVIDIA Tensor Core GPUs, delivers impressive performance metrics, achieving 117 tokens per second on Llama-2-70B-Chat models [3]. Their model offerings include high-quality options like Llama 3.3 70B Turbo and Llama 3.1 405B Turbo, with some models achieving sub-100ms latency [4].\\n\\nTogether.ai has demonstrated remarkable growth, with estimates suggesting $130M in annualized recurring revenue (ARR) in 2024, representing a 400% year-over-year increase [5]. The platform has received positive user feedback, maintaining a 4.8/5.0 rating based on 162 user reviews [6].\\n\\nThe company differentiates itself through competitive pricing and technical innovations, incorporating advanced features like token caching, load balancing, and model quantization [2]. Users particularly praise the platform's straightforward API, reliable performance, and competitive pricing compared to alternatives [7].\\n\\n### Sources\\n[1] https://siliconvalleyjournals.com/company/together-ai/\\n[2] https://www.keywordsai.co/blog/top-10-llm-api-providers\\n[3] https://www.together.ai/blog/together-inference-engine-v1\\n[4] https://artificialanalysis.ai/providers/togetherai\\n[5] https://sacra.com/c/together-ai/\\n[6] https://www.featuredcustomers.com/vendor/together-ai\\n[7] https://www.trustpilot.com/review/together.ai\\n\\n## Groq AI Overview\\n\\nGroq has emerged as a significant player in the AI inference market with its innovative Language Processing Unit (LPU) technology. Independent benchmarks from ArtificialAnalysis.ai demonstrate Groq's impressive performance, with their Llama 2 Chat (70B) API achieving 241 tokens per second - more than double the speed of competing providers [1]. Their total response time for 100 output tokens is just 0.8 seconds, positioning them as a leader in inference speed [2].\\n\\nThe company's core technology, the Tensor Streaming Processor (TSP), delivers 500-700 tokens per second on large language models, representing a 5-10x improvement over Nvidia's latest data center GPUs [3]. This performance advantage has positioned Groq as a compelling alternative in the inference market, particularly for startups seeking cost-effective solutions [4].\\n\\nWith approximately 300 employees, 60% of whom are software engineers, Groq has evolved beyond hardware to become a comprehensive AI solutions provider [5]. The company is strategically positioned to capture a share of the growing inference chip market, which is projected to reach $48 billion by 2027 [6].\\n\\n### Sources\\n[1] https://groq.com/artificialanalysis-ai-llm-benchmark-doubles-axis-to-fit-new-groq-lpu-inference-engine-performance-results/\\n[2] https://groq.com/inference/\\n[3] https://sacra.com/c/groq/\\n[4] https://venturebeat.com/ai/ai-chip-race-groq-ceo-takes-on-nvidia-claims-most-startups-will-use-speedy-lpus-by-end-of-2024/\\n[5] https://www.businessinsider.com/groq-nvidia-software-advantage-cuda-moat-challenge-inference-2024-12?op=1\\n[6] https://generativeaitech.substack.com/p/groq-and-its-impact-on-ai-inference\\n\\n## Market Comparison and Trends\\n\\nThe AI inference market shows distinct positioning among key players Fireworks, Together.ai, and Groq. Fireworks AI differentiates itself through superior speed, leveraging its proprietary FireAttention inference engine for text, image, and audio processing, while maintaining HIPAA and SOC2 compliance for data privacy [1]. Together.ai has demonstrated remarkable growth, reaching an estimated $130M in annualized recurring revenue (ARR) in 2024, representing a 400% year-over-year increase [2].\\n\\nBoth Fireworks and Together.ai focus on providing high-quality open-source models that can compete with proprietary alternatives [1]. Pricing structures vary across providers, with model costs ranging from $0.20 to $3.00 per million tokens for different model sizes and capabilities [3]. Together.ai's business model benefits from GPU price commoditization, allowing them to maintain competitive token pricing while focusing on developer experience and reliable inference across diverse open-source models [2].\\n\\nGroq distinguishes itself by offering quick access to various open-source AI models from major providers like Google, Meta, OpenAI, and Mistral through the OpenRouter API platform [4]. The market shows a trend toward comprehensive platform offerings, with providers competing on factors such as model variety, inference speed, and specialized features for different use cases.\\n\\n### Sources\\n[1] Top 10 AI Inference Platforms in 2025: Comparing LLM API Providers: https://www.helicone.ai/blog/llm-api-providers\\n[2] Together AI revenue, valuation & growth rate | Sacra: https://sacra.com/c/together-ai/\\n[3] Models Leaderboard : Comparison of AI Models & API Providers - Groq AI: https://groq-ai.com/models/\\n[4] Pricing: Compare Groq API Pricing With Other API Providers: https://groq-ai.com/pricing/\\n\\n## Conclusion\\n\\nThe AI inference market shows clear differentiation among key players, with each provider carving out unique value propositions. Together.ai leads in revenue growth with $130M ARR, while Fireworks AI demonstrates strong potential with its recent $552M valuation. Groq distinguishes itself through superior inference speeds, achieving up to 700 tokens per second with its LPU technology.\\n\\n| Metric | Fireworks | Together.ai | Groq |\\n|--------|-----------|-------------|------|\\n| ARR | $6M | $130M | Not disclosed |\\n| Speed (tokens/sec) | Up to 300 | Up to 117 | 500-700 |\\n| Key Differentiator | FP8 quantization | 200+ model access | LPU technology |\\n| Notable Feature | 3x faster than competitors | Token caching | Sub-second response |\\n| Target Market | Enterprise security | Developer platforms | Startup solutions |\\n\\nThe market trends indicate a shift toward comprehensive platform offerings that balance speed, cost-efficiency, and model variety. As the inference chip market approaches $48B by 2027, providers focusing on specialized hardware solutions and optimized infrastructure will likely gain competitive advantages. Success will depend on maintaining the delicate balance between performance, pricing, and platform features while addressing growing enterprise demands for security and reliability.\"}}\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Pass True to approve the report plan (make string match thing) (add things to update user in front end about completion state)\n",
    "async for event in graph.astream(Command(resume=True), thread, stream_mode=\"updates\"):\n",
    "    print(event)\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "# AI Inference Market: Analysis of Fireworks, Together.ai, and Groq\n",
       "\n",
       "The AI inference market is experiencing rapid evolution as companies compete to provide faster, more efficient solutions for deploying and managing AI models. This analysis examines three key players reshaping the landscape: Fireworks, Together.ai, and Groq. Each brings distinct advantages - Fireworks with its specialized features and security focus, Together.ai with its comprehensive platform and impressive growth trajectory, and Groq with its groundbreaking Language Processing Unit technology. As organizations increasingly rely on AI inference capabilities, understanding these providers' strengths and market positions becomes crucial for making informed deployment decisions.\n",
       "\n",
       "## Fireworks AI Overview\n",
       "\n",
       "Fireworks AI has established itself as a significant player in the AI inference market, offering a comprehensive platform for deploying and managing AI models. The company provides access to various high-performance models, including Llama 3.1 405B and Qwen2.5 Coder 32B, which represent their highest quality offerings [1]. Their platform demonstrates impressive performance metrics, with some models achieving speeds up to 300 tokens per second for serverless deployments [2].\n",
       "\n",
       "The company has gained substantial market traction, recently securing $52 million in Series B funding that values the company at $552 million [3]. With an annual revenue of $6 million and a team of 60 employees, Fireworks AI serves notable clients including DoorDash, Quora, and Upwork [4, 5].\n",
       "\n",
       "Their platform differentiates itself through specialized features like FP8 quantization for large models and continuous batching capabilities [6]. Fireworks claims to offer approximately 3x faster speeds compared to competitors like Hugging Face TGI when using the same GPU configuration [2]. The company focuses on providing smaller, production-grade models that can be deployed privately and securely, rather than generic mega models [5].\n",
       "\n",
       "### Sources\n",
       "[1] Fireworks: Models Intelligence, Performance & Price: https://artificialanalysis.ai/providers/fireworks\n",
       "[2] Fireworks Platform Spring 2024 Updates: https://fireworks.ai/blog/spring-update-faster-models-dedicated-deployments-postpaid-pricing\n",
       "[3] Fireworks AI Raises $52M in Series B Funding: https://siliconvalleyjournals.com/fireworks-ai-raises-52m-in-series-b-funding-to-expand-genai-inference-platform/\n",
       "[4] Fireworks AI: Contact Details, Revenue, Funding: https://siliconvalleyjournals.com/company/fireworks-ai/\n",
       "[5] Fireworks AI Valued at $552 Million After New Funding Round: https://www.pymnts.com/news/investment-tracker/2024/fireworks-ai-valued-552-million-dollars-after-new-funding-round/\n",
       "[6] Inference performance - Fireworks AI Docs: https://docs.fireworks.ai/faq/models/inference/performance\n",
       "\n",
       "## Together.ai Overview\n",
       "\n",
       "Together.ai is a comprehensive AI acceleration platform that has quickly emerged as a significant player in the AI inference space since its founding in 2022 [1]. The platform enables developers to access over 200 AI models, offering high-performance inference capabilities with optimized infrastructure [2].\n",
       "\n",
       "The company's Inference Engine, built on NVIDIA Tensor Core GPUs, delivers impressive performance metrics, achieving 117 tokens per second on Llama-2-70B-Chat models [3]. Their model offerings include high-quality options like Llama 3.3 70B Turbo and Llama 3.1 405B Turbo, with some models achieving sub-100ms latency [4].\n",
       "\n",
       "Together.ai has demonstrated remarkable growth, with estimates suggesting $130M in annualized recurring revenue (ARR) in 2024, representing a 400% year-over-year increase [5]. The platform has received positive user feedback, maintaining a 4.8/5.0 rating based on 162 user reviews [6].\n",
       "\n",
       "The company differentiates itself through competitive pricing and technical innovations, incorporating advanced features like token caching, load balancing, and model quantization [2]. Users particularly praise the platform's straightforward API, reliable performance, and competitive pricing compared to alternatives [7].\n",
       "\n",
       "### Sources\n",
       "[1] https://siliconvalleyjournals.com/company/together-ai/\n",
       "[2] https://www.keywordsai.co/blog/top-10-llm-api-providers\n",
       "[3] https://www.together.ai/blog/together-inference-engine-v1\n",
       "[4] https://artificialanalysis.ai/providers/togetherai\n",
       "[5] https://sacra.com/c/together-ai/\n",
       "[6] https://www.featuredcustomers.com/vendor/together-ai\n",
       "[7] https://www.trustpilot.com/review/together.ai\n",
       "\n",
       "## Groq AI Overview\n",
       "\n",
       "Groq has emerged as a significant player in the AI inference market with its innovative Language Processing Unit (LPU) technology. Independent benchmarks from ArtificialAnalysis.ai demonstrate Groq's impressive performance, with their Llama 2 Chat (70B) API achieving 241 tokens per second - more than double the speed of competing providers [1]. Their total response time for 100 output tokens is just 0.8 seconds, positioning them as a leader in inference speed [2].\n",
       "\n",
       "The company's core technology, the Tensor Streaming Processor (TSP), delivers 500-700 tokens per second on large language models, representing a 5-10x improvement over Nvidia's latest data center GPUs [3]. This performance advantage has positioned Groq as a compelling alternative in the inference market, particularly for startups seeking cost-effective solutions [4].\n",
       "\n",
       "With approximately 300 employees, 60% of whom are software engineers, Groq has evolved beyond hardware to become a comprehensive AI solutions provider [5]. The company is strategically positioned to capture a share of the growing inference chip market, which is projected to reach $48 billion by 2027 [6].\n",
       "\n",
       "### Sources\n",
       "[1] https://groq.com/artificialanalysis-ai-llm-benchmark-doubles-axis-to-fit-new-groq-lpu-inference-engine-performance-results/\n",
       "[2] https://groq.com/inference/\n",
       "[3] https://sacra.com/c/groq/\n",
       "[4] https://venturebeat.com/ai/ai-chip-race-groq-ceo-takes-on-nvidia-claims-most-startups-will-use-speedy-lpus-by-end-of-2024/\n",
       "[5] https://www.businessinsider.com/groq-nvidia-software-advantage-cuda-moat-challenge-inference-2024-12?op=1\n",
       "[6] https://generativeaitech.substack.com/p/groq-and-its-impact-on-ai-inference\n",
       "\n",
       "## Market Comparison and Trends\n",
       "\n",
       "The AI inference market shows distinct positioning among key players Fireworks, Together.ai, and Groq. Fireworks AI differentiates itself through superior speed, leveraging its proprietary FireAttention inference engine for text, image, and audio processing, while maintaining HIPAA and SOC2 compliance for data privacy [1]. Together.ai has demonstrated remarkable growth, reaching an estimated $130M in annualized recurring revenue (ARR) in 2024, representing a 400% year-over-year increase [2].\n",
       "\n",
       "Both Fireworks and Together.ai focus on providing high-quality open-source models that can compete with proprietary alternatives [1]. Pricing structures vary across providers, with model costs ranging from $0.20 to $3.00 per million tokens for different model sizes and capabilities [3]. Together.ai's business model benefits from GPU price commoditization, allowing them to maintain competitive token pricing while focusing on developer experience and reliable inference across diverse open-source models [2].\n",
       "\n",
       "Groq distinguishes itself by offering quick access to various open-source AI models from major providers like Google, Meta, OpenAI, and Mistral through the OpenRouter API platform [4]. The market shows a trend toward comprehensive platform offerings, with providers competing on factors such as model variety, inference speed, and specialized features for different use cases.\n",
       "\n",
       "### Sources\n",
       "[1] Top 10 AI Inference Platforms in 2025: Comparing LLM API Providers: https://www.helicone.ai/blog/llm-api-providers\n",
       "[2] Together AI revenue, valuation & growth rate | Sacra: https://sacra.com/c/together-ai/\n",
       "[3] Models Leaderboard : Comparison of AI Models & API Providers - Groq AI: https://groq-ai.com/models/\n",
       "[4] Pricing: Compare Groq API Pricing With Other API Providers: https://groq-ai.com/pricing/\n",
       "\n",
       "## Conclusion\n",
       "\n",
       "The AI inference market shows clear differentiation among key players, with each provider carving out unique value propositions. Together.ai leads in revenue growth with $130M ARR, while Fireworks AI demonstrates strong potential with its recent $552M valuation. Groq distinguishes itself through superior inference speeds, achieving up to 700 tokens per second with its LPU technology.\n",
       "\n",
       "| Metric | Fireworks | Together.ai | Groq |\n",
       "|--------|-----------|-------------|------|\n",
       "| ARR | $6M | $130M | Not disclosed |\n",
       "| Speed (tokens/sec) | Up to 300 | Up to 117 | 500-700 |\n",
       "| Key Differentiator | FP8 quantization | 200+ model access | LPU technology |\n",
       "| Notable Feature | 3x faster than competitors | Token caching | Sub-second response |\n",
       "| Target Market | Enterprise security | Developer platforms | Startup solutions |\n",
       "\n",
       "The market trends indicate a shift toward comprehensive platform offerings that balance speed, cost-efficiency, and model variety. As the inference chip market approaches $48B by 2027, providers focusing on specialized hardware solutions and optimized infrastructure will likely gain competitive advantages. Success will depend on maintaining the delicate balance between performance, pricing, and platform features while addressing growing enterprise demands for security and reliability."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_state = graph.get_state(thread)\n",
    "report = final_state.values.get('final_report')\n",
    "Markdown(report) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
